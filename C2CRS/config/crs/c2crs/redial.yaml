# pretrain没有early stop
# dataset
dataset: ReDial
tokenize:
  rec: nltk
# dataloader
context_truncate: 1024
response_truncate: 30
scale: 1
# model
rec_model: C2CRS_Model
token_emb_dim: 300
kg_emb_dim: 128
num_bases: 8
n_heads: 2
n_layers: 2
ffn_size: 300
dropout: 0.1
attention_dropout: 0.0
relu_dropout: 0.1
learn_positional_embeddings: false
embeddings_scale: true
reduction: false
n_positions: 1024
# optim
pretrain:
  epoch: 50
  batch_size: 256
  optimizer:
    name: Adam
    lr: !!float 1e-3
  lr_bert: !!float 1e-5
rec:
  epoch: 50
  batch_size: 256
  optimizer:
    name: Adam
    lr: !!float 1e-3
  lr_bert: !!float 1e-5
  early_stop: True
  stop_mode: max
  impatience: 3
conv:
  epoch: 100
  batch_size: 256
  optimizer:
    name: Adam
    lr: !!float 1e-3
  lr_scheduler:
    name: ReduceLROnPlateau
    patience: 3
    factor: 0.5
  gradient_clip: 0.1
